$ python 33_nk225_train.py
[0]training loss:       0.000608313753448       0.183474538326[sec/epoch]
[100]training loss:     0.000457610370535       15.4304803705[sec/epoch]
[200]training loss:     0.00028256691917        15.3005952811[sec/epoch]
[300]training loss:     0.00026811687558        15.8193476105[sec/epoch]
[400]training loss:     0.000201548609619       14.5355399489[sec/epoch]
[500]training loss:     0.000202360139652       15.67074651[sec/epoch]
[600]training loss:     0.000177974822094       17.3456133294[sec/epoch]
[700]training loss:     0.000192470227679       17.8815257502[sec/epoch]
[800]training loss:     0.000195337779293       17.8736854196[sec/epoch]
[900]training loss:     0.000182086940516       16.4236330986[sec/epoch]
[1000]training loss:    0.000184139424954       16.1298011589[sec/epoch]
[1100]training loss:    0.000180380004976       15.0787908483[sec/epoch]
[1200]training loss:    0.00017196788556        15.1282033801[sec/epoch]
[1300]training loss:    0.000174094461883       13.7283649802[sec/epoch]
[1400]training loss:    0.000186035315497       9.68612349987[sec/epoch]
[1500]training loss:    0.000172378495336       9.69564963818[sec/epoch]
[1600]training loss:    0.000159366131581       9.69719223976[sec/epoch]
[1700]training loss:    0.000161668135211       9.69071746826[sec/epoch]
[1800]training loss:    0.000166377240811       9.69054533958[sec/epoch]
[1900]training loss:    0.00016114209788        9.69358486891[sec/epoch]
[2000]training loss:    0.000144936774641       9.70371232033[sec/epoch]
[2100]training loss:    0.000148784293972       9.70091609955[sec/epoch]
[2200]training loss:    0.000123721801422       9.68736540079[sec/epoch]
[2300]training loss:    0.000128281029938       9.69165184975[sec/epoch]
[2400]training loss:    0.000124380349962       9.70287599087[sec/epoch]
[2500]training loss:    0.000130294793935       9.69027215004[sec/epoch]
[2600]training loss:    0.000115122156914       9.70087369919[sec/epoch]
[2700]training loss:    0.000111340441638       9.70783793926[sec/epoch]
[2800]training loss:    0.000110222064335       9.71424181938[sec/epoch]
[2900]training loss:    0.000102535783868       9.71217015982[sec/epoch]
[3000]training loss:    0.000109944539615       9.71899128914[sec/epoch]
[3100]training loss:    8.80362014427e-05       9.71897403955[sec/epoch]
[3200]training loss:    0.000118311127704       9.72075775146[sec/epoch]
[3300]training loss:    8.11135490434e-05       9.70850776196[sec/epoch]
[3400]training loss:    6.82066599227e-05       9.70022387981[sec/epoch]
[3500]training loss:    6.72976702753e-05       9.70876730919[sec/epoch]
[3600]training loss:    6.10754618214e-05       9.70063282967[sec/epoch]
[3700]training loss:    5.3387379857e-05        9.71228654146[sec/epoch]
[3800]training loss:    4.90125343956e-05       9.70606320143[sec/epoch]
[3900]training loss:    4.81123640908e-05       9.71263607025[sec/epoch]
[4000]training loss:    4.47638408102e-05       9.71726639986[sec/epoch]
[4100]training loss:    5.02616308178e-05       9.71208972931[sec/epoch]
[4200]training loss:    3.95326301305e-05       9.71933996201[sec/epoch]
[4300]training loss:    3.34434291216e-05       9.7332822299[sec/epoch]
[4400]training loss:    3.26380890916e-05       9.73231852055[sec/epoch]
[4500]training loss:    3.2274036038e-05        9.71636966944[sec/epoch]
[4600]training loss:    3.16875850349e-05       9.73416491985[sec/epoch]
[4700]training loss:    2.45430050512e-05       9.72968092918[sec/epoch]
[4800]training loss:    2.54261646081e-05       11.2571802902[sec/epoch]
[4900]training loss:    2.04342215162e-05       12.2864478993[sec/epoch]
57442.8597779[sec]

